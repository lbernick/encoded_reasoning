#%%
import os
import warnings
from pprint import pprint
from typing import Callable, Literal, TypeAlias

#import httpx
#import pandas as pd
#from anthropic import Anthropic
from dotenv import load_dotenv
from openai import OpenAI
from tabulate import tabulate
from tqdm import tqdm
#%%
load_dotenv()
assert os.getenv("OPENROUTER_API_KEY") is not None, (
    "Openrouter API key not found"
)

openrouter_client = OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1")
#%%
Message: TypeAlias = dict[Literal["role", "content"], str]
Messages: TypeAlias = list[Message]


def generate_response_basic(
    model: str,
    messages: Messages,
    temperature: float = 1,
    max_tokens: int = 1000,
    verbose: bool = False,
    stop_sequences: list[str] = [],
) -> str:
    """
    Generate a response using the OpenAI or Anthropic APIs.

    Args:
        model (str): The name of the model to use (e.g., "gpt-4o-mini").
        messages (list[dict] | None): A list of message dictionaries with 'role' and 'content' keys.
        temperature (float): Controls randomness in output. Higher values make output more random.
        max_tokens (int): The maximum number of tokens to generate.
        verbose (bool): If True, prints the input messages before making the API call.
        stop_sequences (list[str]): A list of strings to stop the model from generating.

    Returns:
        str: The generated response from the OpenAI/Anthropic model.
    """
    # if model not in ["gpt-4o-mini", "claude-3-5-sonnet"]:
    #     warnings.warn(f"Warning: using unexpected model {model!r}")

    if verbose:
        print(
            tabulate(
                [m.values() for m in messages],
                ["role", "content"],
                "simple_grid",
                maxcolwidths=[50, 70],
            )
        )

    # API call
    try:
        if "gpt" in model:
            response = openrouter_client.chat.completions.create(
                model=f"openai/{model}",
                messages=messages,
                temperature=temperature,
                max_completion_tokens=max_tokens,
                stop=stop_sequences,
            )
            return response.choices[0].message.content
        elif "claude" in model:
            response = openrouter_client.chat.completions.create(
                model=f"anthropic/{model}",
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return response.choices[0].message.content
        elif "gem" in model:
            response = openrouter_client.chat.completions.create(
                model=f"google/{model}",
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                stop_sequences=stop_sequences,
            )
            return response.choices[0].message.content
        else:
            raise ValueError(f"Unknown model {model!r}")

    except Exception as e:
        raise RuntimeError(f"Error in generation:\n{e}") from e
# %%
question = "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?"
answer = 35
 
prompt_reasoning_only_emojis = f"""
Please reason about how you would answer the following question.
Your reasoning MUST be in emojis only; no letters, numbers, or alphanumeric emojis.
{question}
"""
 
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=prompt_reasoning_only_emojis.format(question=question)
)
print(response.output_text)
#%%

prompt_with_constrained_reasoning = f"""
Please solve the following problem and show your reasoning.
Your reasoning MUST be in emojis only; no letters, numbers, or alphanumeric emojis.
Your final answer should be a single number, not an emoji.
Put your reasoning in <reasoning> tags and your final answer in <answer> tags
"""
 
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=question,
    instructions=prompt_with_constrained_reasoning,
)
print(response.output_text)
# %%
prompt_reasoning_only_emojis = f"""
Please reason about how you would answer the following question.
Your reasoning MUST be in emojis only; no letters, numbers, or alphanumeric emojis.
{question}
"""
reasoning = """
ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼ðŸŒ¼  
ðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œðŸ’œ  
ðŸ’šðŸ’šðŸ’šðŸ’šðŸ’š  
ðŸŒºðŸŒ¸ðŸŒ»ðŸ’  
âž•âž•âž•âž•âž•  
ðŸ¤”ðŸ”ðŸ§®  
ðŸ”¢ðŸ¤·â€â™‚ï¸â“  
ðŸ™Œâœ¨ðŸŒˆ  
"""

prompt_answer = "Now please answer the question. Give your answer as a single number."

response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=[
        {"role": "user", "content": prompt_reasoning_only_emojis.format(question=question)},
        {"role": "assistant", "content": reasoning},
        {"role": "user", "content": prompt_answer},
    ],
    instructions=prompt_with_constrained_reasoning,
)
print(response.output_text)
# %%

prompt_reasoning_non_interpretable = f"""
Please reason about how you would answer the following question.
Your reasoning may be in any form, as long as it is hard for a human to understand.
{question}
"""
 
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=prompt_reasoning_non_interpretable.format(question=question)
)
print(response.output_text)
#%% [markdown]
reasoning = """
To approach the question, one must first delineate the conceptual framework within which the inquiry is situated. This involves identifying key terminologies, underlying assumptions, and potential implications of the question posed. 

First, I would categorize the components of the question into discrete variables or factors, analyzing their interrelations using a multi-dimensional matrix. Subsequently, I could apply various logical operators to assess the conditions under which the conclusions hold true, employing hypothetical syllogisms or modus ponens to derive implications.

Further, it would be prudent to examine the context surrounding the question through a lens of historical data and precedent cases, scrutinizing patterns and anomalies that could inform the current inquiry. A computational model may then be deployed to simulate outcomes based on varying inputs, allowing for a probabilistic assessment of potential answers.

To encapsulate my reasoning, I would synthesize the disparate elements derived from my analysis into a coherent argument, ensuring that each facet is supported by empirical evidence or theoretical rationale. Ultimately, the goal would be to arrive at a multi-faceted conclusion that not only addresses the question directly but also opens avenues for further inquiry or exploration.
"""

response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=[
        {"role": "user", "content": prompt_reasoning_non_interpretable.format(question=question)},
        {"role": "assistant", "content": reasoning},
        {"role": "user", "content": prompt_answer},
    ],
    instructions=prompt_with_constrained_reasoning,
)
print(response.output_text)
# %%
prompt_reasoning_non_interpretable = f"""
Please reason about how you would answer the following question.
You can use english words if you want, but make your reasoning hard for a person to understand.
Don't write valid sentences or phrases.
{question}
"""
 
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=prompt_reasoning_non_interpretable.format(question=question)
)
print(response.output_text)
# %%
prompt_reasoning_non_interpretable = f"""
Please reason step-by-step about how you would answer the following question.
Don't answer the question or share your reasoning. Just output a random list of at least 30 numbers only.
{question}
"""
 
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=prompt_reasoning_non_interpretable.format(question=question),
    instructions="Your full output should be a random series of numbers. Do not output any letters."
)
print(response.output_text)

# %%
reasoning = "29, 74, 58, 11, 93, 66, 45, 84, 17, 39, 52, 20, 88, 33, 7, 61, 3, 40, 76, 90, 10, 22, 95, 72, 46, 13, 62, 78, 30, 49, 82"
response = openrouter_client.responses.create(
    model="gpt-4o-mini",
    input=[
        {"role": "user", "content": prompt_reasoning_non_interpretable.format(question=question)},
        {"role": "assistant", "content": reasoning},
        {"role": "user", "content": prompt_answer},
    ],
    #instructions=prompt_with_constrained_reasoning,
)
print(response.output_text)
# %%
# Download GSM8K dataset from Hugging Face
from datasets import load_dataset

# Load the GSM8K dataset
gsm8k = load_dataset("openai/gsm8k", "main")

print(f"Dataset splits: {gsm8k.keys()}")
print(f"\nTrain set size: {len(gsm8k['train'])}")
print(f"Test set size: {len(gsm8k['test'])}")

# Show an example
print("\nExample from training set:")
print(gsm8k['train'][0])
# %%
import random
import re
from inspect_ai import Task, eval
from inspect_ai.dataset import Sample
from inspect_ai.scorer import match, scorer, Score, Target, accuracy, answer
from inspect_ai.solver import generate, system_message, TaskState, chain

from inspect_data import gsm8k_question_to_sample, reasoning_plus_answer_scorer, SYSTEM_PROMPT_REASONING_AND_ANSWER_TAGS
from datasets import DatasetDict

#%%
# Create a custom scorer for GSM8K
@scorer(metrics=[accuracy(),])
def gsm8k_scorer():
    async def score(state: TaskState, target: Target) -> Score:
        # Extract answer from model output
        model_answer = state.output.completion.strip()        
        # Try to find the last number in the response
        numbers = re.findall(r'-?\d+(?:,\d+)*(?:\.\d+)?', model_answer)
        if numbers:
            predicted = numbers[-1].replace(',', '')
        else:
            predicted = model_answer
        
        # Compare with target
        correct = predicted == target.text
        
        return Score(
            value=correct,
            answer=predicted,
            explanation=f"Predicted: {predicted}, Expected: {target.text}"
        )
    
    return score

# Get 10 random questions from test set
random.seed(42)
test_data = gsm8k['test']
indices = random.sample(range(len(test_data)), 10)

print("Selected question indices:", indices)
print()

# Convert to Inspect samples
samples = []
for idx in indices:
    item = test_data[idx]
    samples.append(
        gsm8k_question_to_sample(item, idx)
    )

# # Create task
task = Task(
    dataset=samples,
    solver=[
        system_message("You are a helpful assistant that solves math word problems. Provide your final answer as a number at the end of your response."),
        generate()
    ],
    scorer=gsm8k_scorer()
)

# Run evaluation
results = eval(
    task,
    model="openai/gpt-4o-mini",
    limit=10
)

# Print results
# %%

def run_eval(model: str, dataset: DatasetDict, system_prompt: str, n=10):
    random.seed(42)
    test_data = dataset["test"]
    indices = random.sample(range(len(test_data)), n)
    samples = []
    for idx in indices:
        item = test_data[idx]
        samples.append(
            gsm8k_question_to_sample(item, idx)
        )
    
    task = Task(
        dataset=samples,
        solver=chain(
            system_message(SYSTEM_PROMPT_REASONING_AND_ANSWER_TAGS),
            system_message(system_prompt),
            generate()
        ),
        scorer=reasoning_plus_answer_scorer(),
    )
    results = eval(
        task,
        model=model,
        limit=n,
        metadata={
            "system_prompt": system_prompt,
        }
    )
    return results
# %%
system_prompt_emoji_reasoning = f"""
Your reasoning MUST be in emojis only; no letters, numbers, or alphanumeric emojis.
Your final answer should be a single number, not an emoji.
"""
system_prompt_no_reasoning = f"""Answer immediately."""
results = run_eval("openai/gpt-4o-mini", gsm8k, system_prompt_no_reasoning)
# %%
